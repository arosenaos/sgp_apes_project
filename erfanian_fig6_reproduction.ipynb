{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/data/rong4/Data/ERA5/3hourly/quvw_US/specific_humidity/era5.specific_humidity.198205.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'ee688c63-1e42-471a-a237-adc1eb5af77e']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m era5 \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(all_files, combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Open the dataset with chunking applied\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m era5 \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mby_coords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Converting to central time\u001b[39;00m\n\u001b[1;32m     28\u001b[0m era5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m era5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/api.py:1077\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1075\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1077\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [open_(p, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1078\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/api.py:1077\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1075\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1077\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[43mopen_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1078\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/api.py:588\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    577\u001b[0m     decode_cf,\n\u001b[1;32m    578\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    585\u001b[0m )\n\u001b[1;32m    587\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 588\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    595\u001b[0m     backend_ds,\n\u001b[1;32m    596\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:645\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    626\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    644\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 645\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:408\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    403\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    406\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    407\u001b[0m )\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:355\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:417\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:411\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    412\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2540\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2133\u001b[0m, in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2133\u001b[0m, in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/annieenv/lib/python3.9/site-packages/netCDF4/utils.py:32\u001b[0m, in \u001b[0;36m_find_dim\u001b[0;34m(grp, dimname)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sortbylist\u001b[39m(A,B):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# sort one list (A) using the values from another list (B)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [A[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(A)), key\u001b[38;5;241m=\u001b[39mB\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m)]\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_dim\u001b[39m(grp, dimname):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# find Dimension instance given group and name.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# look in current group, and parents.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     group \u001b[38;5;241m=\u001b[39m grp\n\u001b[1;32m     36\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Base path where the folders are located\n",
    "base_path = '/data/rong4/Data/ERA5/3hourly/quvw_US'\n",
    "\n",
    "# Define the range of years and months\n",
    "years = [str(year) for year in range(1979, 2019)]\n",
    "\n",
    "def get_files(folder, component):\n",
    "    # Use glob to find files matching the component pattern\n",
    "    files = glob.glob(os.path.join(base_path, folder, f\"era5.{component}.*.nc\"))\n",
    "    # Filter files by years and months\n",
    "    filtered_files = [f for f in files if any(year in f for year in years)]\n",
    "    return filtered_files\n",
    "\n",
    "# Get the files for each component\n",
    "u_files = get_files('u_component_of_wind', 'u_component_of_wind')\n",
    "v_files = get_files('v_component_of_wind', 'v_component_of_wind')\n",
    "q_files = get_files('specific_humidity', 'specific_humidity')\n",
    "\n",
    "all_files = u_files + v_files + q_files\n",
    "\n",
    "# # Open all datasets at once\n",
    "era5 = xr.open_mfdataset(all_files, combine='by_coords')\n",
    "\n",
    "# Open the dataset with chunking applied\n",
    "era5 = xr.open_mfdataset(all_files, combine='by_coords')\n",
    "\n",
    "# Converting to central time\n",
    "era5['time'] = era5['time'] - pd.Timedelta(hours=6)\n",
    "\n",
    "era5sgp = era5.sel(latitude=slice(39.0, 30.0), longitude=slice(-105.0, -95.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time subsets for fig 2c) and 2f) \n",
    "\n",
    "era2011 = era5sgp.sel(time=slice('2011-01-01', '2011-12-31'))\n",
    "eraclim = era5sgp.sel(time=slice('1979-01-01', '2018-12-31'))\n",
    "\n",
    "# daytime composites -> averages over 18 UTC (12 LST) and 0 UTC (18 LST)\n",
    "# nighttime composites -> averages over 6 UTC (0 LST) and 12 UTC (6 LST)\n",
    "\n",
    "_2011night = era2011.sel(time=era2011['time'].dt.hour.isin([0, 6]))\n",
    "_2011day = era2011.sel(time=era2011['time'].dt.hour.isin([12, 18]))\n",
    "\n",
    "_2011night_monthly = _2011night.resample(time='ME').mean()\n",
    "_2011day_monthly = _2011day.resample(time='ME').mean()\n",
    "\n",
    "_climnight = era5clim.sel(time=eraclim['time'].dt.hour.isin([0, 6]))\n",
    "_climday = era5clim.sel(time=eraclim['time'].dt.hour.isin([12, 18]))\n",
    "\n",
    "_climnight_monthly = _climnight.groupby('time.month').mean('time')\n",
    "_climday_monthly = _climday.groupby('time.month').mean('time')\n",
    "\n",
    "_all_times = {\n",
    "    '2011_night_monthly': _2011night_monthly,\n",
    "    '2011_day_monthly': _2011day_monthly,\n",
    "    'clim_night_monthly': _climnight_monthly,\n",
    "    'clim_day_monthly': _climday_monthly\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moisture_budget_profiles(u, v, q, lat, lon):\n",
    "\n",
    "    R = 6371000  # Radius of Earth (meters)\n",
    "    \n",
    "    lon_grid, lat_grid = np.meshgrid(np.radians(lon), np.radians(lat))\n",
    "    grid_dist = np.radians(lat[1]) - np.radians(lat[0])\n",
    "    \n",
    "    # shaped as (#lons, #lats) so first row represents all values for first latitude (eg: 30,30,30...)\n",
    "    cos_correction = R * np.cos(lat_grid)\n",
    "    dy_cos_correction = np.cos(lat_grid)\n",
    "    \n",
    "    # Initialize 3D arrays for derivatives\n",
    "    dudx = np.zeros_like(u)\n",
    "    dvdy = np.zeros_like(v)\n",
    "    dqdx = np.zeros_like(q)\n",
    "    dqdy = np.zeros_like(q)\n",
    "    \n",
    "    # Loop through each pressure level\n",
    "    for k in range(u.shape[0]):  # Loop over pressure levels\n",
    "        v_dy = v[k] * dy_cos_correction\n",
    "        q_dy = q[k] * dy_cos_correction\n",
    "\n",
    "        # Central differences for interior points\n",
    "    \n",
    "        dudx[k, :, 1:-1] = (u[k, :, 2:] - u[k, :, :-2]) / (2 * grid_dist)\n",
    "        dvdy[k, 1:-1, :] = (v_dy[2:, :] - v_dy[:-2, :]) / (2 * grid_dist)\n",
    "        dqdx[k, :, 1:-1] = (q[k, :, 2:] - q[k, :, :-2]) / (2 * grid_dist)\n",
    "        dqdy[k, 1:-1, :] = (q_dy[2:, :] - q_dy[:-2, :]) / (2 * grid_dist)\n",
    "\n",
    "        # Boundary points (one-sided differences)\n",
    "        # Left and right boundaries (x-direction)\n",
    "        dudx[k, :, 0] = (u[k, :, 1] - u[k, :, 0]) / grid_dist  # forward difference\n",
    "        dudx[k, :, -1] = (u[k, :, -1] - u[k, :, -2]) / grid_dist  # backward difference\n",
    "        \n",
    "        dqdx[k, :, 0] = (q[k, :, 1] - q[k, :, 0]) / grid_dist\n",
    "        dqdx[k, :, -1] = (q[k, :, -1] - q[k, :, -2]) / grid_dist\n",
    "\n",
    "        # Top and bottom boundaries (y-direction)\n",
    "        dvdy[k, 0, :] = (v_dy[1, :] - v_dy[0, :]) / grid_dist  # forward difference\n",
    "        dvdy[k, -1, :] = (v_dy[-1, :] - v_dy[-2, :]) / grid_dist  # backward difference\n",
    "        \n",
    "        dqdy[k, 0, :] = (q_dy[1, :] - q_dy[0, :]) / grid_dist\n",
    "        dqdy[k, -1, :] = (q_dy[-1, :] - q_dy[-2, :]) / grid_dist\n",
    "\n",
    "        # Apply cos_correction for spherical coordinates\n",
    "        dudx[k] = (1 / cos_correction) * dudx[k]\n",
    "        dvdy[k] = (1 / cos_correction) * dvdy[k]\n",
    "        dqdy[k] = (1 / cos_correction) * dqdy[k]\n",
    "        dqdx[k] = (1 / cos_correction) * dqdx[k]\n",
    "\n",
    "    # Moisture advection for each pressure level\n",
    "    moisture_advection = u * dqdx + v * dqdy\n",
    "    \n",
    "    zonal_advection = -(u * dqdx)\n",
    "    \n",
    "    meridional_advection = -(v * dqdy)\n",
    "\n",
    "    # Dynamical convergence for each pressure level\n",
    "    dynamical_convergence = q * dudx + q * dvdy\n",
    "\n",
    "    # Total moisture flux convergence\n",
    "    mfc = dynamical_convergence + moisture_advection\n",
    "    # Units --> 1/s\n",
    "    return zonal_advection, meridional_advection\n",
    "\n",
    "\n",
    "\n",
    "# Vertically integrated moisture flux convergence and its components\n",
    "def vertically_integrated_mfc(u_levels, v_levels, q_levels, pressure_levels, latitude, longitude):\n",
    "    \"\"\"\n",
    "    u_levels, v_levels, q_levels: 3D arrays (pressure, lat, lon) of wind and humidity at different pressure levels\n",
    "    dx, dy: grid spacing in meters (uniform for simplicity)\n",
    "    pressure_levels: 1D array of pressure levels in Pascals (Pa), typically ordered from top to surface\n",
    "    \"\"\"\n",
    "    g = 9.81  # gravitational acceleration in m/s^2\n",
    "    rho_water = 1000 # kg/m^3\n",
    "    scale_factor = 1000 * 60 * 60 * 24 # to convert from m/s --> mm/day in final computation\n",
    "    \n",
    "    zonal_adv_levels, meridional_adv_levels = moisture_budget_profiles(u_levels, v_levels, q_levels, latitude, longitude)\n",
    "    \n",
    "    # Use trapezoidal rule to integrate MFC and its components over pressure\n",
    "    dp = np.diff(pressure_levels)  # Differences between pressure levels (positive when integrating from top to surface)\n",
    "    \n",
    "    zonal_adv_profile = []\n",
    "    merid_adv_profile = []\n",
    "    \n",
    "    # The integrations (for full column) are 2D\n",
    "    zonal_adv_int = np.zeros_like(zonal_adv_levels[0], dtype=np.float64)\n",
    "    meridional_adv_int = np.zeros_like(meridional_adv_levels[0], dtype=np.float64)\n",
    "#     dyn_conv_integrated = np.zeros_like(dyn_conv_levels[0], dtype=np.float64)  \n",
    "#     moist_adv_integrated = np.zeros_like(moist_adv_levels[0], dtype=np.float64) \n",
    "    \n",
    "    # Trapezoidal integration: sum over pressure levels\n",
    "\n",
    "    for i in range(len(dp)):\n",
    "        zonal_adv_int += 0.5 * (zonal_adv_levels[i] + zonal_adv_levels[i+1]) * dp[i]\n",
    "        meridional_adv_int += 0.5 * (meridional_adv_levels[i] + meridional_adv_levels[i+1]) * dp[i]\n",
    "                \n",
    "        zonal_adv_profile.append(0.5 * (zonal_adv_levels[i] + zonal_adv_levels[i+1]) * dp[i])\n",
    "        merid_adv_profile.append(0.5 * (meridional_adv_levels[i] + meridional_adv_levels[i+1]) * dp[i])\n",
    "\n",
    "#         mfc_integrated += 0.5 * (mfc_levels[i] + mfc_levels[i+1]) * dp[i]\n",
    "#         dyn_conv_integrated += 0.5 * (dyn_conv_levels[i] + dyn_conv_levels[i+1]) * dp[i]\n",
    "#         moist_adv_integrated += 0.5 * (moist_adv_levels[i] + moist_adv_levels[i+1]) * dp[i]\n",
    "\n",
    "    # Convert to vertically integrated MFC and its components by dividing by g\n",
    "    \n",
    "    zonal_adv_integrated = zonal_adv_int * (1/g) * (1/rho_water) * scale_factor\n",
    "    meridional_adv_integrated = meridional_adv_int * (1/g) * (1/rho_water) * scale_factor\n",
    "    \n",
    "    zonal_adv_profile = np.array(zonal_adv_profile)\n",
    "    merid_adv_profile = np.array(merid_adv_profile)\n",
    "    \n",
    "    zonal_adv_profile = zonal_adv_profile * (1/g) * (1/rho_water) * scale_factor\n",
    "    merid_adv_profile = merid_adv_profile * (1/g) * (1/rho_water) * scale_factor\n",
    "    \n",
    "#     mfc_integrated = mfc_integrated * (1/g) * (1/rho_water) * scale_factor \n",
    "#     dyn_conv_integrated = dyn_conv_integrated * (1/g) * (1/rho_water) * scale_factor\n",
    "#     moist_adv_integrated = moist_adv_integrated * (1/g) * (1/rho_water) * scale_factor \n",
    "\n",
    "    # Units --> mm/day\n",
    "    return zonal_adv_integrated, meridional_adv_integrated, zonal_adv_profile, merid_adv_profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6 c) & f) reproduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop through the datasets\n",
    "for df_name, df in _all_times.items():\n",
    "    print(df_name)\n",
    "    identifier = df_name\n",
    "    u = df['u'].load().data[:, :, ::-1, :]  \n",
    "    v = df['v'].load().data[:, :, ::-1, :]  \n",
    "    q = df['q'].load().data[:, :, ::-1, :] \n",
    "    levels = df['level'].data * 100 \n",
    "    latitude = df['latitude'].data[::-1]\n",
    "    longitude = df['longitude'].data  \n",
    "    \n",
    "    zonals = []\n",
    "    merids = []\n",
    "    \n",
    "    # Loop through each month \n",
    "    for i in range(u.shape[0]):\n",
    "        # Calculate zonal and meridional advection (will be Dask arrays)\n",
    "        zonal_adv_int, meridional_adv_int = vertically_integrated_mfc(u[i], v[i], q[i], levels, latitude, longitude)\n",
    "        # Append mean values (these are Dask arrays)\n",
    "        zonals.append(zonal_adv_int.mean())\n",
    "        merids.append(meridional_adv_int.mean())\n",
    "\n",
    "    # Store the results in a dictionary with Dask arrays\n",
    "    results[identifier] = {\n",
    "        'zonal': zonals,  # List of Dask arrays\n",
    "        'meridional': merids  # List of Dask arrays\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting zonal advection\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "months=[\"Jan\", \"Feb\", \"March\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "plt.plot(months, results['2011_night_monthly']['zonal'], color='red', linestyle='--', label='2011-night')\n",
    "plt.plot(months, results['2011_day_monthly']['zonal'], color='red', label='2011-day')\n",
    "plt.plot(months, results['clim_night_monthly']['zonal'], color='blue', linestyle='--', label='Climatology-night')\n",
    "plt.plot(months, results['clim_day_monthly']['zonal'], color='blue', label='Climatology-day')\n",
    "plt.axhline(0, color='grey', linewidth=2)\n",
    "plt.ylabel(\"mm/day\")\n",
    "plt.title(\"Vertically Integrated Zonal Advection\")\n",
    "plt.ylim(-5,2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plotting meridional advection\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "months=[\"Jan\", \"Feb\", \"March\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "plt.plot(months, results['2011_night_monthly']['meridional'], color='red', linestyle='--', label='2011-night')\n",
    "plt.plot(months, results['2011_day_monthly']['meridional'], color='red', label='2011-day')\n",
    "plt.plot(months, results['clim_night_monthly']['meridional'], color='blue', linestyle='--', label='Climatology-night')\n",
    "plt.plot(months, results['clim_day_monthly']['meridional'], color='blue', label='Climatology-day')\n",
    "plt.axhline(0, color='grey', linewidth=2)\n",
    "plt.title(\"Vertically Integrated Meridional Advection\")\n",
    "plt.ylabel(\"mm/day\")\n",
    "# plt.ylim(-5,2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6 a) b) d) and f) reproduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era2011_night_plus_day = era2011.sel(time=era2011['time'].dt.hour.isin([0, 6, 12, 18]))\n",
    "era2011monthly = era2011_night_plus_day.resample(time='ME').mean()\n",
    "u_2011 = era2011monthly['u'].load().data[:, :, ::-1, :]  \n",
    "v_2011 = era2011monthly['v'].load().data[:, :, ::-1, :]  \n",
    "q_2011 = era2011monthly['q'].load().data[:, :, ::-1, :] \n",
    "levels = era2011monthly['level'].data * 100 \n",
    "latitude = era2011monthly['latitude'].data[::-1]\n",
    "longitude = era2011monthly['longitude'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_profile = []\n",
    "merid_profile = []\n",
    "    \n",
    "# Loop through each month \n",
    "for i in range(u_2011.shape[0]):\n",
    "    _, _, _2011_zonal_adv, _2011_merid_adv = vertically_integrated_mfc(u_2011[i], v_2011[i], q_2011[i], levels, latitude, longitude)\n",
    "    zonal_profile.append(_2011_zonal_adv)\n",
    "    merid_profile.append(_2011_merid_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months_zonal_profiles = []\n",
    "for month in zonal_profile: \n",
    "    month_profile = np.mean(month, axis=(1, 2))\n",
    "    all_months_zonal_profiles.append(month_profile)\n",
    "    \n",
    "all_months_merid_profiles = []\n",
    "for month in merid_profile: \n",
    "    month_profile = np.mean(month, axis=(1, 2))\n",
    "    all_months_merid_profiles.append(month_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6b) and e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advection_profiles = [all_months_zonal_profiles, all_months_merid_profiles]\n",
    "titles = ['Zonal', 'Meridional']\n",
    "\n",
    "pressure_levels = era2011monthly['level'].data[2:]\n",
    "\n",
    "for i, arr in enumerate(advection_profiles):  # Use enumerate to get both index and array\n",
    "    \n",
    "    #subsetting only for pressure levels up to 100 \n",
    "    hovmoller_data = np.array(arr)[:,2:]\n",
    "    print(np.min(hovmoller_data), np.max(hovmoller_data))\n",
    "\n",
    "    levels = np.array([-0.5, -0.2, -0.1, -0.05, -0.01, 0.01, 0.05, 0.1, 0.2, 0.5])\n",
    "\n",
    "    # Create a custom colormap with a white segment between -0.01 and 0.01\n",
    "    colors = ['#67001f', '#b2182b', '#d6604d', '#f4a582', 'white', 'white', '#92c5de', '#4393c3', '#2166ac', '#053061']\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_coolwarm\", colors, N=len(levels)-1)\n",
    "\n",
    "    # Normalize the data based on defined levels\n",
    "    norm = mcolors.BoundaryNorm(levels, ncolors=len(levels)-1, clip=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5)) #width, height\n",
    "\n",
    "    plt.imshow(hovmoller_data.T, aspect='auto', origin='lower', cmap=cmap, norm=norm, interpolation='bilinear')\n",
    "    \n",
    "    plt.ylabel('hPa')\n",
    "\n",
    "    plt.xticks(np.arange(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "    plt.yticks(np.arange(27), pressure_levels)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    cbar = plt.colorbar(label='mm/day', ticks=levels)\n",
    "    cbar.ax.set_yticklabels([f'{level:.2f}' for level in levels])\n",
    "\n",
    "    # Show the plot with the correct title\n",
    "    plt.title('2011 {} Advection'.format(titles[i]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = eraclim.groupby('time.month').mean('time')\n",
    "u_clim = clim['u'].load().data[:, :, ::-1, :]  \n",
    "v_clim = clim['v'].load().data[:, :, ::-1, :]  \n",
    "q_clim = clim['q'].load().data[:, :, ::-1, :] \n",
    "levels = clim['level'].data * 100 \n",
    "latitude = clim['latitude'].data[::-1]\n",
    "longitude = clim['longitude'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_profile_clim = []\n",
    "merid_profile_clim = []\n",
    "    \n",
    "# Loop through each month \n",
    "for i in range(u_clim.shape[0]):\n",
    "    _, _, clim_zonal_adv, clim_merid_adv = vertically_integrated_mfc(u_clim[i], v_clim[i], q_clim[i], levels, latitude, longitude)\n",
    "    zonal_profile_clim.append(clim_zonal_adv)\n",
    "    merid_profile_clim.append(clim_merid_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months_zonal_profiles_clim = []\n",
    "for month in zonal_profile_clim: \n",
    "    month_profile = np.mean(month, axis=(1, 2))\n",
    "    all_months_zonal_profiles_clim.append(month_profile)\n",
    "    \n",
    "all_months_merid_profiles_clim = []\n",
    "for month in merid_profile_clim: \n",
    "    month_profile = np.mean(month, axis=(1, 2))\n",
    "    all_months_merid_profiles_clim.append(month_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6a) and d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advection_profiles = [all_months_zonal_profiles_clim, all_months_merid_profiles_clim]\n",
    "titles = ['Zonal', 'Meridional']\n",
    "\n",
    "pressure_levels = clim['level'].data[2:]\n",
    "\n",
    "for i, arr in enumerate(advection_profiles):  # Use enumerate to get both index and array\n",
    "    \n",
    "    hovmoller_data = np.array(arr)[:,2:]\n",
    "    print(np.min(hovmoller_data), np.max(hovmoller_data))\n",
    "\n",
    "    levels = np.array([-0.3, -0.2, -0.1, -0.05, -0.01, 0.01, 0.05, 0.1, 0.2, 0.4])\n",
    "\n",
    "    # Create a custom colormap with a white segment between -0.01 and 0.01\n",
    "    colors = ['#67001f', '#b2182b', '#d6604d', '#f4a582', 'white', 'white', '#92c5de', '#4393c3', '#2166ac', '#053061']\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_coolwarm\", colors, N=len(levels)-1)\n",
    "\n",
    "    # Normalize the data based on defined levels\n",
    "    norm = mcolors.BoundaryNorm(levels, ncolors=len(levels)-1, clip=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5)) #width, height\n",
    "\n",
    "    plt.imshow(hovmoller_data.T, aspect='auto', origin='lower', cmap=cmap, norm=norm, interpolation='bilinear')\n",
    "    \n",
    "    plt.ylabel('hPa')\n",
    "\n",
    "    plt.xticks(np.arange(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "    plt.yticks(np.arange(27), pressure_levels)\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    cbar = plt.colorbar(label='mm/day', ticks=levels)\n",
    "    cbar.ax.set_yticklabels([f'{level:.2f}' for level in levels])\n",
    "\n",
    "    # Show the plot with the correct title\n",
    "#     plt.title('Hovmöller Diagram of Climatology {} Advection'.format(titles[i]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcs = []\n",
    "# advs = []\n",
    "# dyns = []\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# for df_name, df in _all_times.items():\n",
    "#     identifier = df_name\n",
    "#     u = df['u'].load().data[:,:,::-1,:] # m/s\n",
    "#     v = df['v'].load().data[:,:,::-1,:] # m/s\n",
    "#     q = df['q'].load().data[:,:,::-1,:] # kg/kg\n",
    "#     levels = monthly_means['level'].load().data * 100 # convert to Pa\n",
    "#     latitude = monthly_means['latitude'].load().data[::-1] # deg\n",
    "#     longitude = monthly_means['longitude'].load().data # deg\n",
    "    \n",
    "#     zonals = []\n",
    "#     merids = []\n",
    "    \n",
    "#     for i in range(u.shape[0]):   \n",
    "#         zonal_adv_int, meridional_adv_int = vertically_integrated_mfc(u[i], v[i], q[i], levels, latitude, longitude)\n",
    "#         zonals.append(np.mean(zonal_adv_int))\n",
    "#         merids.append(np.mean(meridional_adv_int))\n",
    "        \n",
    "#     results[identifier] = {\n",
    "#         'zonal': np.array(zonals),\n",
    "#         'meridional': np.array(merids)\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # selecting a single time dimension for now \n",
    "# time = 100044\n",
    "# print(era5sgp['time'].data[time])\n",
    "# u_levels = era5sgp['u'][time].load().data[:,::-1,:]\n",
    "# v_levels = era5sgp['v'][time].load().data[:,::-1,:]\n",
    "# q_levels = era5sgp['q'][time].load().data[:,::-1,:]\n",
    "# levels = era5sgp['level'].load().data\n",
    "# latitude = era5sgp['latitude'].load().data[::-1]\n",
    "# longitude = era5sgp['longitude'].load().data\n",
    "\n",
    "# # Calculate vertically integrated MFC, dynamical convergence, and moisture advection\n",
    "# mfc, dyn, adv = vertically_integrated_mfc(u_levels, v_levels, q_levels, levels, latitude, longitude)\n",
    "\n",
    "# plt.hist(mfc)\n",
    "# print(np.max(mfc))\n",
    "# print(np.max(dyn))\n",
    "# print(np.max(adv))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manually checking at grid point (30,-105) -(v * dqdy)\n",
    "\n",
    "# v = monthly_means['v'].data[:,:,::-1,:]\n",
    "\n",
    "# q = monthly_means['q'].data[:,::-1,:]\n",
    "\n",
    "# v = v[0][0][0][0]\n",
    "\n",
    "# R = 6371000\n",
    "\n",
    "# cos_factor = 1/(R*np.cos(np.radians(30)))\n",
    "\n",
    "# dist = 0.00436\n",
    "\n",
    "# dqdy = ((np.cos(np.radians(lats[1])))*q[0][1][0] - (np.cos(np.radians(lats[0])))*q[0][0][0])/dist\n",
    "\n",
    "# adv = -(cos_factor)*(v*dqdy)\n",
    "\n",
    "# q[0][1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annieenv",
   "language": "python",
   "name": "annieenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
