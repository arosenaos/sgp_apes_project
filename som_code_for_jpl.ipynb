{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'sigma': 0.1, 'x': 4, 'y': 4}, Best Quantization Error: 28.092783524302263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from minisom import MiniSom\n",
    "\n",
    "#X_feat contains daily average Z500 for individual grid points \n",
    "#column name explanation: for example, \"z50025.0220.0\" means Z500 at point lat=25.0, lon=220.0 \n",
    "X_feat = pd.read_csv('X_feat.csv', index_col=0)\n",
    "\n",
    "#subsetting for all rows and all Z500 columns (excluding \"day\" column)\n",
    "X = X_feat.iloc[:, 1:].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#hyperparameter options: if you want this to run faster as you're learning the code, you can just remove the number of search options for each variable\n",
    "param_grid = {\n",
    "    'x': [2,3,4],\n",
    "    'y': [2,3,4],\n",
    "    'learning_rate': [0.01, 0.1, 0.25, 0.5, 1],\n",
    "    'sigma': [0.1, 0.5, 1.0, 1.5, 2]\n",
    "}\n",
    "\n",
    "# all combinations of hyperparameters\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# initialize variables to track the best configuration\n",
    "best_params = None\n",
    "\n",
    "best_quantization_error = float('inf')\n",
    "\n",
    "# function to calculate quantization error: measures the average distance between each data point and its corresponding BMU in the SOM\n",
    "def quantization_error(som, data):\n",
    "    \n",
    "    error = 0\n",
    "    \n",
    "    for x in data:\n",
    "        \n",
    "        #difference between x (from x_scaled) and weights for the winning node, then take the norm of that vector to get the total distance\n",
    "        error += np.linalg.norm(x - som.get_weights()[som.winner(x)])\n",
    "    \n",
    "    #for each SOM, calculate the average QE\n",
    "    return error / len(data)\n",
    "\n",
    "#grid search\n",
    "for params in grid:\n",
    "    \n",
    "    som = MiniSom(x=params['x'], y=params['y'], input_len=X_scaled.shape[1], sigma=params['sigma'], learning_rate=params['learning_rate'])\n",
    "    \n",
    "    som.random_weights_init(X_scaled)\n",
    "    \n",
    "    som.train_random(data=X_scaled, num_iteration=10000)\n",
    "    \n",
    "    qe = quantization_error(som, X_scaled)\n",
    "    \n",
    "    #best_quantization_error starts at infinity, then with each subsequent QE calculation, updates best QE & params if new QE is less than previous\n",
    "    \n",
    "    if qe < best_quantization_error:\n",
    "        \n",
    "        best_quantization_error = qe\n",
    "        \n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best params: {best_params}, Best Quantization Error: {best_quantization_error}\")\n",
    "\n",
    "#SOM training below: uses best parameters derived from grid search \n",
    "np.random.seed(42)\n",
    "\n",
    "n_rows = best_params['x']\n",
    "\n",
    "n_columns = best_params['y']\n",
    "\n",
    "sigma = best_params['sigma']\n",
    "\n",
    "learning_rate = best_params['learning_rate']\n",
    "\n",
    "som = MiniSom(n_rows, n_columns, X_scaled.shape[1], sigma=sigma, learning_rate=learning_rate, random_seed=42)\n",
    "\n",
    "som.random_weights_init(X_scaled)\n",
    "\n",
    "#add verbose = True if you want more detail\n",
    "#you can also use train_batch instead, depending on what you prefer\n",
    "som.train_random(X_scaled, num_iteration=10000)\n",
    "\n",
    "#creating a best matching unit (bmu) column to assign each day to the closest matching node according to the SOM result\n",
    "bmus = []\n",
    "\n",
    "for x in X_scaled:\n",
    "    \n",
    "    bmu = som.winner(x)\n",
    "    \n",
    "    bmus.append(bmu)\n",
    "\n",
    "X_feat['bmu'] = bmus\n",
    "\n",
    "#get_weights() extracts the Z500 pattern for every node in the SOM (# of nodes is defined by n_rows x n_columns)\n",
    "#for example: weights[0,0] will access the node in the first row & first column of the SOM (with the data i provided, weights[0,0] will have same size as # of grid points = 2080)\n",
    "weights = som.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annieenv",
   "language": "python",
   "name": "annieenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
